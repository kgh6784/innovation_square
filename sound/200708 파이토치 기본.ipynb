{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sigmoid 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "i = [0,1,2,3,4,5,6,7,8,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00000000e+00 2.71828183e+00 7.38905610e+00 2.00855369e+01\n",
      " 5.45981500e+01 1.48413159e+02 4.03428793e+02 1.09663316e+03\n",
      " 2.98095799e+03 8.10308393e+03]\n",
      "12818.308050524603\n",
      "[7.80134161e-05 2.12062451e-04 5.76445508e-04 1.56694135e-03\n",
      " 4.25938820e-03 1.15782175e-02 3.14728583e-02 8.55520989e-02\n",
      " 2.32554716e-01 6.32149258e-01]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "e_i = np.exp(i)\n",
    "sum_e_i = np.sum(e_i)\n",
    "p_i = e_i/sum_e_i\n",
    "print(e_i)\n",
    "print(sum_e_i)\n",
    "print(p_i)\n",
    "print(np.sum(p_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000078\t0.000212\t0.000576\t0.001567\t0.004259\t0.011578\t0.031473\t0.085552\t0.232555\t0.632149\t"
     ]
    }
   ],
   "source": [
    "for item in p_i:\n",
    "    print(\"{:8f}\".format(item), end=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[1, 2, 1],\n",
    "                             [1, 3, 2],\n",
    "                             [1, 3, 4],\n",
    "                             [1, 5, 5],\n",
    "                             [1, 7, 5],\n",
    "                             [1, 2, 5],\n",
    "                             [1, 6, 6],\n",
    "                             [1, 7, 7]\n",
    "                            ])\n",
    "y_train = torch.LongTensor([2, 2, 2, 1, 1, 1, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = torch.FloatTensor([[2, 1, 1], [3, 1, 2], [3, 3, 4]])\n",
    "y_test = torch.LongTensor([2, 2, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## zero_grad()와 with torch.no_grad()\n",
    "`zero_grad()`는 안의 value를 zero로 만드는 것\n",
    "`with torch.no_grad()` 는 gradient를 아예 계산하지 않겠다. 예측할 때 사용한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 두 가지 모드\n",
    "파이토치에는 두 가지 모드가 있는데 (1) 학습 모드, (2) 예측 모드이다.\n",
    "- 모델 학습 모드일 때 예측 모드일 때 동작해야하는 방식이 다른 layer를 가지고 있다.\n",
    "- [1] batch normalizatin, [2] dropout\n",
    "- (1) (2) 모드를 변경 시켜주는 함수가 `eval()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
